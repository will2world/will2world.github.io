---
date: '2025-11-03T16:50:07+09:00'
draft: false
toc: true
comments: true
authors:
  - 이정욱
  # - 손준호
tags:
  - nlp
title: 'RAG'
---


## RAG의 개요

LLM(Large Language Model)은 방대한 양의 데이터를 기반으로 수십억 개의 파라미터에 사전학습하여 질문에 대한 답변을 독창적으로 생성합니다. 
기존의 Language Model과 비교하여 답변의 정확도는 올라갔지만, 문제점은 아직 존재합니다.
1. 방대한 양의 데이터로 학습하기 때문에 신뢰할 수 없는 응답을 생성합니다.
2. 과거의 데이터로 학습을 하기 때문에 최신 정보를 실시간으로 반영할 수 없습니다.
3. 모델의 크기가 수십 억개의 파라미터로 구성되어 있기 때문에 최신 정보로 재학습 시 비용, 시간이 많이 소요됩니다.

RAG(Retrieval-Augmented Generation)는 이러한 문제를 해결하기 위한 접근 방식입니다. 
우선 단어의 뜻 하나하나를 살펴봅시다.
1. 'Retrieval'은 검색한다는 의미로 사용자의 질문을 '어디선가에서 검색하여 가져온다'라는 의미를 가집니다.
2. 'Augmented'는 증강되었다라는 뜻으로 'LLM에 검색된 데이터를 보태어 본다'라는 의미를 가집니다.
3. 'Generation'은 LLM의 목적 중 질문에 대한 응답생성 부분을 뜻합니다.

따라서, RAG는 'LLM이 사용자 질문에 대하여 답변을 생성할 때, 사용자의 질문에 대해 어디선가에서 검색하고 보태어 생성한다.' 라고 이해할 수 있습니다.

Facebook AI Research는 2020년, RAG를 통해 최신 정보에 대해 알지 못하고 신뢰할 수 없는 답변을 생성하는 LLM의 한계를 극복합니다.

## RAG의 작동방식

RAG는 다음의 단계를 따라 작동합니다.
1. 벡터화(Vectorization)
사용자의 질문을 벡터화하는 단계입니다. 컴퓨터에 사람의 언어를 입력하기 위해서는 숫자로 표현해야 합니다. 따라서 자연어는 수백에서 수천 개의 숫자로 이루어진 벡터로 구성됩니다. 이 과정을 임베딩(Embedding)이라 부르며 비슷한 자연어끼리는 같은 벡터공간에 위치하게 됩니다.

2. 검색(Retrieval)
벡터 데이터베이스(Vector Database) 혹은 벡터 스토어(Vector Store)에 새롭게 발생한 데이터를 저장합니다.
새롭게 발생한 데이터 역시 벡터로 변환되어 있으며, 질문 벡터와 가장 유사한 데이터를 찾아냅니다.
여기서 유사도는 벡터 간의 코사인 유사도(Cosine Similarity)나 유클리드 거리(Euclidean distance)와 같은 수학적 방법을 사용합니다.

3. 생성(Generation)
사용자의 질문과 유사한 데이터를 검색한 뒤, 검색된 정보와 질문을 모두 활용하여 답변을 생성합니다. 

## RAG 문제

LLM의 한계를 극복하기 위한 RAG는 현재 우리가 사용하는 AI Chat bot에서 당연히 사용되고 있습니다.
RAG는 모델의 학습 이후 정보에 접근 할 수 있다는 큰 장점이 있고, 검색된 데이터를 기반으로 답변을 생성하기 때문에 신뢰성 측면에서도 큰 기여를 하고 있습니다.
하지만 다음과 같은 문제가 존재합니다.

* Retrieval 과정에서 단순한 키워드 기반 유사도 사용 시 비슷하지 않는 문장을 검색한다. 예를 들어 "바다의 온도 상승이 해양 생태계에 미치는 영향은?" 

## References
* Facebook AI Research, 2021. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks

{{< authors-inline >}}
